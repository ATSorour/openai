% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/create_classification.R
\name{create_classification}
\alias{create_classification}
\title{Create classification}
\usage{
create_classification(
  model = c("ada", "babbage", "curie", "davinci"),
  query,
  examples = NULL,
  file = NULL,
  labels = NULL,
  search_model = c("ada", "babbage", "curie", "davinci"),
  temperature = 0,
  logprobs = NULL,
  max_examples = 200,
  logit_bias = NULL,
  return_prompt = FALSE,
  return_metadata = FALSE,
  expand = NULL,
  user = NULL,
  openai_api_key = Sys.getenv("OPENAI_API_KEY"),
  openai_organization = NULL
)
}
\arguments{
\item{model}{required; defaults to \code{"ada"}; a length one character vector,
one among \code{"ada"}, \code{"babbage"}, \code{"curie"}, and \code{"davinci"}. ID of the
engine to use for completion.}

\item{query}{required; a length one character vector. Query to be classified.}

\item{examples}{optional; defaults to \code{NULL}; a list. A list of examples with
labels, in the following format: \code{list(c("The movie is so interesting.", "Positive"), c("It is quite boring.", "Negative"), ...)}. All the label
strings will be normalized to be capitalized. You should specify either
\code{examples} or \code{file}, but not both.}

\item{file}{optional; defaults to \code{NULL}; a length one character vector. The
ID of the uploaded file that contains training examples. See
\code{\link[=upload_file]{upload_file()}} for how to upload a file of the desired format and
purpose. You should specify either \code{examples} or \code{file}, but not both.}

\item{labels}{optional; defaults to \code{NULL}; an arbitrary length character
vector. The set of categories being classified. If not specified, candidate
labels will be automatically collected from the examples you provide. All
the label strings will be normalized to be capitalized.}

\item{search_model}{required; defaults to \code{ada}; a length one character
vector, one among \code{"ada"}, \code{"babbage"}, \code{"curie"}, and \code{"davinci"}. ID of
the engine to use for \code{\link[=create_search]{create_search()}}.}

\item{temperature}{required; defaults to \code{0}; a length one numeric vector
with the value between \code{0} and \code{2}. What sampling \code{temperature} to use.
Higher values means the model will take more risks. Try \code{0.9} for more
creative applications, and \code{0} (argmax sampling) for ones with a
well-defined answer.}

\item{logprobs}{optional; defaults to \code{NULL}; a length one numeric vector
with the integer value between \code{0} and \code{5}. Include the log probabilities
on the \code{logprobs} most likely tokens, as well the chosen tokens. For
example, if \code{logprobs} is \code{5}, the API will return a list of the 5 most
likely tokens. The API will always return the \code{logprob} of the sampled
token, so there may be up to \code{logprobs+1} elements in the response. The
maximum value for logprobs is \code{5}. If you need more than this, please
contact \email{support@openai.com} and describe your use case. When
\code{logprobs} is set, \code{completion} will be automatically added into \code{expand}
to get the logprobs.}

\item{max_examples}{required; defaults to \code{200}; a length one numeric vector
with the integer value greater than \code{0}. The maximum number of examples to
be ranked by \code{\link[=create_search]{create_search()}} when using file. Setting it to a higher
value leads to improved accuracy but with increased latency and cost.}

\item{logit_bias}{optional; defaults to \code{NULL}; a named list. Modify the
likelihood of specified tokens appearing in the completion. Accepts a list
that maps tokens (specified by their token ID in the GPT tokenizer) to an
associated bias value from \code{-100} to \code{100}. You can use this tokenizer tool
(which works for both GPT-2 and GPT-3) to convert text to token IDs.
Mathematically, the bias is added to the logits generated by the model
prior to sampling. The exact effect will vary per model, but values between
\code{-1} and \code{1} should decrease or increase likelihood of selection; values
like \code{-100} or \code{100} should result in a ban or exclusive selection of the
relevant token. As an example, you can pass \code{list("50256" = -100)} to
prevent the \verb{<|endoftext|>} token from being generated.}

\item{return_prompt}{required; defaults to \code{FALSE}; a length one logical
vector. If set to \code{TRUE}, the returned JSON will include a "prompt" field
containing the final prompt that was used to request a completion. This is
mainly useful for debugging purposes.}

\item{return_metadata}{required; defaults to \code{FALSE}; a length one logical
vector. A special boolean flag for showing metadata. If set to \code{TRUE}, each
document entry in the returned JSON will contain a "metadata" field. This
flag only takes effect when \code{file} is set.}

\item{expand}{optional; defaults to \code{NULL}; a list elements of which are
among \code{completion} and \code{file}. If an object name is in the list, we provide
the full information of the object; otherwise, we only provide the object
ID. Currently we support \code{completion} and \code{file} objects for expansion.}

\item{user}{optional; defaults to \code{NULL}; a length one character vector. A
unique identifier representing your end-user, which will help OpenAI to
monitor and detect abuse.}

\item{openai_api_key}{required; defaults to \code{Sys.getenv("OPENAI_API_KEY")}
(i.e., the value is retrieved from the \code{.Renviron} file); a length one
character vector. Specifies OpenAI API key.}

\item{openai_organization}{optional; defaults to \code{NULL}; a length one
character vector. Specifies OpenAI organization.}
}
\value{
Returns a list, elements of which contain label and other
supplementary information.
}
\description{
\ifelse{html}{\href{https://lifecycle.r-lib.org/articles/stages.html#deprecated}{\figure{lifecycle-deprecated.svg}{options: alt='[Deprecated]'}}}{\strong{[Deprecated]}}

\strong{Note:} This endpoint is deprecated and will be removed on December 3,
2022. Please see \href{https://help.openai.com/en/articles/6272941-classifications-transition-guide}{Classifications Transition Guide}
for details.

Classifies the specified \code{query} using provided examples. See \href{https://beta.openai.com/docs/api-reference/classifications/create}{this page} for
details.
}
\details{
Given a query and a set of labeled examples, the model will predict
the most likely label for the query. Useful as a drop-in replacement for any
ML classification or text-to-label task. Classifies the specified \code{query}
using provided examples. The endpoint first
\href{https://beta.openai.com/docs/api-reference/searches}{searches} over the
labeled examples to select the ones most relevant for the particular query.
Then, the relevant examples are combined with the query to construct a prompt
to produce the final label via the
\href{https://beta.openai.com/docs/api-reference/completions}{completions}
endpoint. Labeled examples can be provided via an uploaded \code{file}, or
explicitly listed in the request using the examples parameter for quick tests
and small scale use cases. Related guide:
\href{https://beta.openai.com/docs/guides/classifications}{Classification}.
}
\examples{
\dontrun{
create_classification(
    search_model = "ada",
    model = "curie",
    examples = list(
        c("A happy moment", "Positive"),
        c("I am sad.", "Negative"),
        c("I am feeling awesome", "Positive")
    ),
    query = "I'm ok",
    labels = c("Positive", "Negative", "Neutral")
)
}
}
