#' Create classification
#'
#' @description `r lifecycle::badge("deprecated")`
#'
#' **Note:** This endpoint is deprecated and will be removed on December 3,
#' 2022. Please see [Classifications Transition
#' Guide](https://help.openai.com/en/articles/6272941-classifications-transition-guide)
#' for details.
#'
#' Classifies the specified `query` using provided examples. See [this
#' page](https://beta.openai.com/docs/api-reference/classifications/create) for
#' details.
#'
#' @details Given a query and a set of labeled examples, the model will predict
#' the most likely label for the query. Useful as a drop-in replacement for any
#' ML classification or text-to-label task. Classifies the specified `query`
#' using provided examples. The endpoint first
#' [searches](https://beta.openai.com/docs/api-reference/searches) over the
#' labeled examples to select the ones most relevant for the particular query.
#' Then, the relevant examples are combined with the query to construct a prompt
#' to produce the final label via the
#' [completions](https://beta.openai.com/docs/api-reference/completions)
#' endpoint. Labeled examples can be provided via an uploaded `file`, or
#' explicitly listed in the request using the examples parameter for quick tests
#' and small scale use cases. Related guide:
#' [Classification](https://beta.openai.com/docs/guides/classifications).
#'
#' @param model required; defaults to `"ada"`; a length one character vector,
#'   one among `"ada"`, `"babbage"`, `"curie"`, and `"davinci"`. ID of the
#'   engine to use for completion.
#' @param query required; a length one character vector. Query to be classified.
#' @param examples optional; defaults to `NULL`; a list. A list of examples with
#'   labels, in the following format: `list(c("The movie is so interesting.",
#'   "Positive"), c("It is quite boring.", "Negative"), ...)`. All the label
#'   strings will be normalized to be capitalized. You should specify either
#'   `examples` or `file`, but not both.
#' @param file optional; defaults to `NULL`; a length one character vector. The
#'   ID of the uploaded file that contains training examples. See
#'   [upload_file()] for how to upload a file of the desired format and
#'   purpose. You should specify either `examples` or `file`, but not both.
#' @param labels optional; defaults to `NULL`; an arbitrary length character
#'   vector. The set of categories being classified. If not specified, candidate
#'   labels will be automatically collected from the examples you provide. All
#'   the label strings will be normalized to be capitalized.
#' @param search_model required; defaults to `ada`; a length one character
#'   vector, one among `"ada"`, `"babbage"`, `"curie"`, and `"davinci"`. ID of
#'   the engine to use for [create_search()].
#' @param temperature required; defaults to `0`; a length one numeric vector
#'   with the value between `0` and `2`. What sampling `temperature` to use.
#'   Higher values means the model will take more risks. Try `0.9` for more
#'   creative applications, and `0` (argmax sampling) for ones with a
#'   well-defined answer.
#' @param logprobs optional; defaults to `NULL`; a length one numeric vector
#'   with the integer value between `0` and `5`. Include the log probabilities
#'   on the `logprobs` most likely tokens, as well the chosen tokens. For
#'   example, if `logprobs` is `5`, the API will return a list of the 5 most
#'   likely tokens. The API will always return the `logprob` of the sampled
#'   token, so there may be up to `logprobs+1` elements in the response. The
#'   maximum value for logprobs is `5`. If you need more than this, please
#'   contact \email{support@openai.com} and describe your use case. When
#'   `logprobs` is set, `completion` will be automatically added into `expand`
#'   to get the logprobs.
#' @param max_examples required; defaults to `200`; a length one numeric vector
#'   with the integer value greater than `0`. The maximum number of examples to
#'   be ranked by [create_search()] when using file. Setting it to a higher
#'   value leads to improved accuracy but with increased latency and cost.
#' @param logit_bias optional; defaults to `NULL`; a named list. Modify the
#'   likelihood of specified tokens appearing in the completion. Accepts a list
#'   that maps tokens (specified by their token ID in the GPT tokenizer) to an
#'   associated bias value from `-100` to `100`. You can use this tokenizer tool
#'   (which works for both GPT-2 and GPT-3) to convert text to token IDs.
#'   Mathematically, the bias is added to the logits generated by the model
#'   prior to sampling. The exact effect will vary per model, but values between
#'   `-1` and `1` should decrease or increase likelihood of selection; values
#'   like `-100` or `100` should result in a ban or exclusive selection of the
#'   relevant token. As an example, you can pass `list("50256" = -100)` to
#'   prevent the `<|endoftext|>` token from being generated.
#' @param return_prompt required; defaults to `FALSE`; a length one logical
#'   vector. If set to `TRUE`, the returned JSON will include a "prompt" field
#'   containing the final prompt that was used to request a completion. This is
#'   mainly useful for debugging purposes.
#' @param return_metadata required; defaults to `FALSE`; a length one logical
#'   vector. A special boolean flag for showing metadata. If set to `TRUE`, each
#'   document entry in the returned JSON will contain a "metadata" field. This
#'   flag only takes effect when `file` is set.
#' @param expand optional; defaults to `NULL`; a list elements of which are
#'   among `completion` and `file`. If an object name is in the list, we provide
#'   the full information of the object; otherwise, we only provide the object
#'   ID. Currently we support `completion` and `file` objects for expansion.
#' @param user optional; defaults to `NULL`; a length one character vector. A
#'   unique identifier representing your end-user, which will help OpenAI to
#'   monitor and detect abuse.
#' @param openai_api_key required; defaults to `Sys.getenv("OPENAI_API_KEY")`
#'   (i.e., the value is retrieved from the `.Renviron` file); a length one
#'   character vector. Specifies OpenAI API key.
#' @param openai_organization optional; defaults to `NULL`; a length one
#'   character vector. Specifies OpenAI organization.
#' @return Returns a list, elements of which contain label and other
#'   supplementary information.
#' @examples \dontrun{
#' create_classification(
#'     search_model = "ada",
#'     model = "curie",
#'     examples = list(
#'         c("A happy moment", "Positive"),
#'         c("I am sad.", "Negative"),
#'         c("I am feeling awesome", "Positive")
#'     ),
#'     query = "I'm ok",
#'     labels = c("Positive", "Negative", "Neutral")
#' )
#' }
#' @export
create_classification <- function(
        model = c("ada", "babbage", "curie", "davinci"),
        query,
        examples = NULL,
        file = NULL,
        labels = NULL,
        search_model = c("ada", "babbage", "curie", "davinci"),
        temperature = 0,
        logprobs = NULL,
        max_examples = 200,
        logit_bias = NULL,
        return_prompt = FALSE,
        return_metadata = FALSE,
        expand = NULL,
        user = NULL,
        openai_api_key = Sys.getenv("OPENAI_API_KEY"),
        openai_organization = NULL
) {

    lifecycle::deprecate_warn(
        "0.1.0",
        "create_answer()",
        details = paste(
            "See the official transition guide:",
            "https://help.openai.com/en/articles/6272941-classifications-transition-guide"
        )
    )

    model <- match.arg(model)
    search_model <- match.arg(search_model)

    #---------------------------------------------------------------------------
    # Validate arguments

    assertthat::assert_that(
        assertthat::is.string(model),
        assertthat::noNA(model)
    )

    assertthat::assert_that(
        assertthat::is.string(query),
        assertthat::noNA(query)
    )

    if (!is.null(examples)) {
        assertthat::assert_that(
            is.list(examples)
        )
    }

    if (!is.null(file)) {
        assertthat::assert_that(
            assertthat::is.string(file),
            assertthat::noNA(file)
        )
    }

    if ((is.null(examples) && is.null(file)) ||
        (!is.null(examples) && !is.null(file))) {
        stop("You should specify either examples or a file, but not both.")
    }

    if (!is.null(labels)) {
        assertthat::assert_that(
            is.character(labels),
            assertthat::noNA(labels)
        )
    }

    assertthat::assert_that(
        assertthat::is.string(search_model),
        assertthat::noNA(search_model)
    )

    assertthat::assert_that(
        assertthat::is.number(temperature),
        assertthat::noNA(temperature),
        value_between(temperature, 0, 2)
    )

    if (!is.null(logprobs)) {
        assertthat::assert_that(
            assertthat::is.count(logprobs + 1),
            value_between(logprobs, 0, 5)

        )
    }

    assertthat::assert_that(
        assertthat::is.count(max_examples)
    )

    if (!is.null(logit_bias)) {
        assertthat::assert_that(
            is.list(logit_bias)
        )
    }

    assertthat::assert_that(
        assertthat::is.flag(return_prompt),
        assertthat::noNA(return_prompt)
    )

    assertthat::assert_that(
        assertthat::is.flag(return_metadata),
        assertthat::noNA(return_metadata)
    )

    if (!is.null(expand)) {
        assertthat::assert_that(
            is.list(expand)
        )
    }

    if (!is.null(user)) {
        assertthat::assert_that(
            assertthat::is.string(user),
            assertthat::noNA(user)
        )
    }

    assertthat::assert_that(
        assertthat::is.string(openai_api_key),
        assertthat::noNA(openai_api_key)
    )

    if (!is.null(openai_organization)) {
        assertthat::assert_that(
            assertthat::is.string(openai_organization),
            assertthat::noNA(openai_organization)
        )
    }

    #---------------------------------------------------------------------------
    # Build path parameters

    task <- "classifications"

    base_url <- glue::glue("https://api.openai.com/v1/{task}")

    headers <- c(
        "Authorization" = paste("Bearer", openai_api_key),
        "Content-Type" = "application/json"
    )

    if (!is.null(openai_organization)) {
        headers["OpenAI-Organization"] <- openai_organization
    }

    #---------------------------------------------------------------------------
    # Build request body

    body <- list()
    body[["model"]] <- model
    body[["query"]] <- query
    body[["examples"]] <- examples
    body[["file"]] <- file
    body[["labels"]] <- labels
    body[["search_model"]] <- search_model
    body[["temperature"]] <- temperature
    body[["logprobs"]] <- logprobs
    body[["logit_bias"]] <- logit_bias
    body[["return_prompt"]] <- return_prompt
    body[["return_metadata"]] <- return_metadata
    body[["expand"]] <- expand
    body[["user"]] <- user

    #---------------------------------------------------------------------------
    # Make a request and parse it

    response <- httr::POST(
        url = base_url,
        httr::add_headers(.headers = headers),
        body = body,
        encode = "json"
    )

    verify_mime_type(response)

    parsed <- response %>%
        httr::content(as = "text", encoding = "UTF-8") %>%
        jsonlite::fromJSON(flatten = TRUE)

    #---------------------------------------------------------------------------
    # Check whether request failed and return parsed

    if (httr::http_error(response)) {
        paste0(
            "OpenAI API request failed [",
            httr::status_code(response),
            "]:\n\n",
            parsed$error$message
        ) %>%
            stop(call. = FALSE)
    }

    parsed

}
